{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import urllib, json\n",
    "import requests\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# try:\n",
    "#     os.remove(\"ent-landmarks_new.txt\")\n",
    "# except OSError:\n",
    "#     pass\n",
    "\n",
    "# file = open(\"ent-landmarks_new.txt\", \"w\") \n",
    "# file.write(\"image_name\"+ \"\\t\"+\"contour_left2\"+ \"\\t\"+\"contour_right2\"+\"\\t\"+\\\n",
    "#            \"right_eyebrow_left_corner\"+\"\\t\"+\"left_eyebrow_left_corner\"+\"\\t\"+\\\n",
    "#            \"contour_chin\"+\"\\t\"+\"mouth_lower_lip_bottom\"+\"\\t\"+\\\n",
    "#            \"mouth_lower_lip_top\"+\"\\t\"+\"\\n\")\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:03,  3.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "2it [00:05,  2.88s/it]\u001b[A\u001b[A\n",
      "\n",
      "3it [00:07,  2.73s/it]\u001b[A\u001b[A\n",
      "\n",
      "4it [00:10,  2.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "5it [00:12,  2.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "6it [00:15,  2.52s/it]\u001b[A\u001b[A\n",
      "\n",
      "7it [00:18,  2.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "8it [00:21,  2.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "9it [00:23,  2.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "10it [00:25,  2.54s/it]\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "for img_filename in tqdm(glob.iglob('/Users/tanvipriya/Documents/quarter_materials/3) Fall 2018/impression_personality/VC_old_data/e/*/*.jpeg')):\n",
    "    with open(img_filename, 'rb') as f:\n",
    "        img_data = f.read()\n",
    "        http_url=\"https://api-us.faceplusplus.com/facepp/v3/detect\"\n",
    "        data={ \"api_key\": \"8hvaF5CZTdoyaIOmxGNWbcPZzCTKJNUS\",\n",
    "              \"api_secret\":\"Pas8ETS8wSzEAFOeGh_r8frqGE3rhwU5\",\n",
    "              \"return_landmark\":1} \n",
    "        files= {\"image_file\": open(img_filename,'rb')}\n",
    "        response=requests.post(http_url,data=data,files=files)\n",
    "        time.sleep(2)\n",
    "        req_con=response.content.decode('utf-8')\n",
    "        index=img_filename.rfind(\"/\")\n",
    "        img_name=img_filename[index+1:]\n",
    "        resp_dict = json.loads(req_con)\n",
    "        try: \n",
    "            file = open(\"ent-landmarks_new.txt\", \"a\") \n",
    "            file.write(img_name+ \"\\t\"+str(resp_dict['faces'][0][\"landmark\"][\"contour_left2\"])\n",
    "                       + \"\\t\"+str(resp_dict['faces'][0][\"landmark\"][\"contour_right2\"])\n",
    "                       + \"\\t\"+str(resp_dict['faces'][0][\"landmark\"][\"right_eyebrow_left_corner\"])\n",
    "                       + \"\\t\"+str(resp_dict['faces'][0][\"landmark\"][\"left_eyebrow_left_corner\"])\n",
    "                       + \"\\t\"+str(resp_dict['faces'][0][\"landmark\"][\"contour_chin\"])\n",
    "                       + \"\\t\"+str(resp_dict['faces'][0][\"landmark\"][\"mouth_lower_lip_bottom\"])\n",
    "                       + \"\\t\"+str(resp_dict['faces'][0][\"landmark\"][\"mouth_lower_lip_top\"])\n",
    "                       + \"\\t\"+\"\\n\")\n",
    "        except:\n",
    "            continue\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = {}\n",
    "\n",
    "def clean_up_values(string):\n",
    "    split = re.split('[, }]', string)\n",
    "    x = float(split[4])\n",
    "    y = float(split[1])\n",
    "    return (x,y)\n",
    "\n",
    "file1 = open(\"ent-landmarks.txt\", \"r\") \n",
    "for line in file1:\n",
    "    if line.startswith(\"image_name\"):\n",
    "        pass\n",
    "    else:\n",
    "        line_split = line.split(\"\\t\")\n",
    "        image_name = line_split[0]\n",
    "        distances[image_name] = {}\n",
    "\n",
    "        distances[image_name][\"contour_left2\"] = clean_up_values(line_split[1])\n",
    "        distances[image_name][\"contour_right2\"] = clean_up_values(line_split[2])\n",
    "        distances[image_name][\"right_eyebrow_left_corner\"] = clean_up_values(line_split[3])\n",
    "        distances[image_name][\"left_eyebrow_left_corner\"] = clean_up_values(line_split[4])\n",
    "        distances[image_name][\"contour_chin\"] = clean_up_values(line_split[5])\n",
    "        distances[image_name][\"mouth_lower_lip_bottom\"] = clean_up_values(line_split[6])\n",
    "        distances[image_name][\"mouth_lower_lip_top\"] = clean_up_values(line_split[7])\n",
    "        \n",
    "        width = distance.euclidean(distances[image_name][\"contour_left2\"], \n",
    "                                   distances[image_name][\"contour_right2\"])\n",
    "        distances[image_name][\"width\"] = width\n",
    "        right_brow = distances[image_name][\"right_eyebrow_left_corner\"]\n",
    "        left_brow = distances[image_name][\"left_eyebrow_left_corner\"]\n",
    "        crest_center = (0.5*(right_brow[0]+left_brow[0]), 0.5*(right_brow[1]+left_brow[1]))\n",
    "        distances[image_name][\"crest_center\"] = crest_center\n",
    "        length = distance.euclidean(distances[image_name][\"contour_chin\"], \n",
    "                                   distances[image_name][\"crest_center\"])\n",
    "        distances[image_name][\"length\"] = length\n",
    "        distances[image_name][\"Width_to_Height_Ratio\"] = 1.0*width/length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(distances, open('distances.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guru2",
   "language": "python",
   "name": "guru2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
