{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "import urllib, json\n",
    "import requests\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial import distance\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open(\"ent-landmarks_new.txt\", \"r\") \n",
    "for line in file1:\n",
    "    if line.startswith(\"img_name\"):\n",
    "        landmark_name_list = (line.split(\"\\t\"))[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = {}\n",
    "\n",
    "def clean_up_values(string):\n",
    "    split = re.split('[, }]', string)\n",
    "    x = float(split[4])\n",
    "    y = float(split[1])\n",
    "    return (x,y)\n",
    "\n",
    "file1 = open(\"ent-landmarks_new.txt\", \"r\")\n",
    "\n",
    "feature_matrix = []\n",
    "image_name_list = []\n",
    "\n",
    "for line in file1:\n",
    "    if line.startswith(\"img_name\"):\n",
    "        pass\n",
    "    else:\n",
    "        feature_vector = None\n",
    "        line_split = line.split(\"\\t\")\n",
    "        image_name = line_split[0]\n",
    "        distances[image_name] = {}\n",
    "        \n",
    "        for indx, land in enumerate(landmark_name_list):\n",
    "            distances[image_name][land] = clean_up_values(line_split[indx+1])\n",
    "#         print(distances)\n",
    "#         break\n",
    "        \n",
    "        dict_ = distances[image_name]\n",
    "        \n",
    "        ## 1) FACE LENGTH:-\n",
    "        right_brow = dict_[\"right_eyebrow_left_corner\"]\n",
    "        left_brow = dict_[\"left_eyebrow_left_corner\"]\n",
    "        dict_[\"crest_center\"] = (0.5*(right_brow[0]+left_brow[0]), 0.5*(right_brow[1]+left_brow[1]))\n",
    "        dict_[\"face_length\"] = distance.euclidean(dict_[\"mouth_lower_lip_bottom\"], \n",
    "                                         dict_[\"crest_center\"])\n",
    "        feature_vector = [dict_[\"face_length\"]]\n",
    "        feature_vector_name = [\"face_length\"]\n",
    "        \n",
    "        ## 2) FACE WIDTH EYE LEVEL:-\n",
    "        dict_[\"face_width_eye_level\"] = distance.euclidean(dict_[\"contour_left1\"], dict_[\"contour_right1\"])\n",
    "        feature_vector.append(dict_[\"face_width_eye_level\"])\n",
    "        feature_vector_name.append(\"face_width_eye_level\")\n",
    "        \n",
    "        ## 3) FACE WIDTH MOUTH LEVEL:-  \n",
    "        dict_[\"face_width_mouth_level\"] = distance.euclidean(dict_[\"contour_left5\"], dict_[\"contour_right5\"])\n",
    "        feature_vector.append(dict_[\"face_width_mouth_level\"])\n",
    "        feature_vector_name.append(\"face_width_mouth_level\")\n",
    "        \n",
    "        ## 4) distance between pupils\n",
    "        dict_[\"distance_between_pupils\"] = distance.euclidean(dict_[\"left_eye_pupil\"], dict_[\"right_eye_pupil\"])\n",
    "        feature_vector.append(dict_[\"distance_between_pupils\"])\n",
    "        feature_vector_name.append(\"distance_between_pupils\")\n",
    "        \n",
    "        ## 5) ratio between 2 and 3\n",
    "        dict_[\"ratio_face_width_eye_level_face_width_mouth_level\"] = 1.0*dict_[\"face_width_eye_level\"]/dict_[\"face_width_mouth_level\"]\n",
    "        feature_vector.append(dict_[\"ratio_face_width_eye_level_face_width_mouth_level\"])\n",
    "        feature_vector_name.append(\"ratio_face_width_eye_level_face_width_mouth_level\")\n",
    "        \n",
    "        ## 6) ratio between 1 and 2\n",
    "        dict_[\"ratio_face_length_face_width_eye_level\"] = 1.0*dict_[\"face_length\"]/dict_[\"face_width_eye_level\"]\n",
    "        feature_vector.append(dict_[\"ratio_face_length_face_width_eye_level\"])\n",
    "        feature_vector_name.append(\"ratio_face_length_face_width_eye_level\")\n",
    "        \n",
    "        ## 7) ratio between 1 and 3 \n",
    "        dict_[\"ratio_face_length_face_width_mouth_level\"] = 1.0*dict_[\"face_length\"]/dict_[\"face_width_mouth_level\"]\n",
    "        feature_vector.append(dict_[\"ratio_face_length_face_width_mouth_level\"])\n",
    "        feature_vector_name.append(\"ratio_face_length_face_width_mouth_level\")\n",
    "        \n",
    "        ## 8) ratio between 4 and 2 \n",
    "        dict_[\"ratio_distance_between_pupils_face_width_eye_level\"]  = 1.0*dict_[\"distance_between_pupils\"]/dict_[\"face_width_eye_level\"]\n",
    "        feature_vector.append(dict_[\"ratio_distance_between_pupils_face_width_eye_level\"])\n",
    "        feature_vector_name.append(\"ratio_distance_between_pupils_face_width_eye_level\")\n",
    "        \n",
    "        ## 9) right eyebrow thickness (above pupil):-  \n",
    "        dict_[\"right_eyebrow_thickness\"] = distance.euclidean(dict_[\"left_eyebrow_upper_middle\"], \n",
    "                                                                dict_[\"left_eyebrow_lower_middle\"])\n",
    "        feature_vector.append(dict_[\"right_eyebrow_thickness\"])\n",
    "        feature_vector_name.append(\"right_eyebrow_thickness\")\n",
    "        \n",
    "        ## 10) left eyebrow thickness (above pupil):-  \n",
    "        dict_[\"left_eyebrow_thickness\"] = distance.euclidean(dict_[\"right_eyebrow_upper_middle\"], \n",
    "                                                                dict_[\"right_eyebrow_lower_middle\"])\n",
    "        feature_vector.append(dict_[\"left_eyebrow_thickness\"])\n",
    "        feature_vector_name.append(\"left_eyebrow_thickness\")\n",
    "        \n",
    "        ## 11) right eyebrow arch – height difference between highest point and inner edge\n",
    "        dict_[\"right_eyebrow_arch\"] = max(dict_[\"right_eyebrow_right_corner\"][1], \n",
    "                                          dict_[\"right_eyebrow_upper_right_quarter\"][1],\n",
    "                                          dict_[\"right_eyebrow_upper_middle\"][1],\n",
    "                                          dict_[\"right_eyebrow_upper_left_quarter\"][1],\n",
    "                                         dict_[\"right_eyebrow_left_corner\"][1])\n",
    "        feature_vector.append(dict_[\"right_eyebrow_arch\"])\n",
    "        feature_vector_name.append(\"right_eyebrow_arch\")\n",
    "        \n",
    "        ## 12) left eyebrow arch – height difference between highest point and inner edge\n",
    "        dict_[\"left_eyebrow_arch\"] = max(dict_[\"left_eyebrow_right_corner\"][1], \n",
    "                                          dict_[\"left_eyebrow_upper_right_quarter\"][1],\n",
    "                                          dict_[\"left_eyebrow_upper_middle\"][1],\n",
    "                                          dict_[\"left_eyebrow_upper_left_quarter\"][1],\n",
    "                                         dict_[\"left_eyebrow_left_corner\"][1])\n",
    "        feature_vector.append(dict_[\"left_eyebrow_arch\"])\n",
    "        feature_vector_name.append(\"left_eyebrow_arch\")\n",
    "        \n",
    "        ## 15) right eye width\n",
    "        dict_[\"right_eye_height\"] = distance.euclidean(dict_[\"right_eye_top\"], dict_[\"right_eye_bottom\"])\n",
    "        feature_vector.append(dict_[\"right_eye_height\"])\n",
    "        feature_vector_name.append(\"right_eye_height\")\n",
    "        \n",
    "        ## 16) left eye width\n",
    "        dict_[\"left_eye_height\"] = distance.euclidean(dict_[\"left_eye_top\"], dict_[\"left_eye_bottom\"])\n",
    "        feature_vector.append(dict_[\"left_eye_height\"])\n",
    "        feature_vector_name.append(\"left_eye_height\")\n",
    "        \n",
    "        ## 15) right eye width\n",
    "        dict_[\"right_eye_width\"] = distance.euclidean(dict_[\"right_eye_right_corner\"], \n",
    "                                                      dict_[\"right_eye_left_corner\"])\n",
    "        feature_vector.append(dict_[\"right_eye_width\"])\n",
    "        feature_vector_name.append(\"right_eye_width\")\n",
    "        \n",
    "        ## 16) left eye width\n",
    "        dict_[\"left_eye_width\"] = distance.euclidean(dict_[\"left_eye_left_corner\"], \n",
    "                                                     dict_[\"left_eye_right_corner\"])\n",
    "        feature_vector.append(dict_[\"left_eye_width\"])\n",
    "        feature_vector_name.append(\"left_eye_width\")\n",
    "        \n",
    "        ## 17) right eye size\n",
    "        dict_[\"right_eye_size\"] = dict_[\"right_eye_height\"]*dict_[\"right_eye_width\"]\n",
    "        feature_vector.append(dict_[\"right_eye_size\"])\n",
    "        feature_vector_name.append(\"right_eye_size\")\n",
    "        \n",
    "        ## 18) left eye size\n",
    "        dict_[\"left_eye_size\"] = dict_[\"left_eye_height\"]*dict_[\"left_eye_width\"]\n",
    "        feature_vector.append(dict_[\"left_eye_size\"])\n",
    "        feature_vector_name.append(\"left_eye_size\")\n",
    "        \n",
    "        ## 20) nose width at nostrils\n",
    "        dict_[\"nose_width_at_nostrils\"] = distance.euclidean(dict_[\"nose_left\"], dict_[\"nose_right\"])\n",
    "        feature_vector.append(dict_[\"nose_width_at_nostrils\"])\n",
    "        feature_vector_name.append(\"nose_width_at_nostrils\")\n",
    "        \n",
    "        ## 21) nose length\n",
    "        dict_[\"nose_top_center\"] = (0.5*(dict_[\"nose_contour_left1\"][0]+dict_[\"nose_contour_right1\"][0]), \n",
    "                        0.5*(dict_[\"nose_contour_left1\"][1]+dict_[\"nose_contour_right1\"][1]))\n",
    "        dict_[\"nose_length\"] = distance.euclidean(dict_[\"nose_contour_lower_middle\"],\n",
    "                                                  dict_[\"nose_top_center\"])\n",
    "        feature_vector.append(dict_[\"nose_length\"])\n",
    "        feature_vector_name.append(\"nose_length\")\n",
    "        \n",
    "        ## 22) nose size\n",
    "        dict_[\"nose_size\"] = dict_[\"nose_length\"]*dict_[\"nose_width_at_nostrils\"]\n",
    "        feature_vector.append(dict_[\"nose_size\"])\n",
    "        feature_vector_name.append(\"nose_size\")\n",
    "        \n",
    "        ## 23) cheekbone width (2-3)\n",
    "        dict_[\"cheekbone_width\"] = dict_[\"face_width_eye_level\"] - dict_[\"face_width_mouth_level\"]\n",
    "        feature_vector.append(dict_[\"cheekbone_width\"])\n",
    "        feature_vector_name.append(\"cheekbone_width\")\n",
    "        \n",
    "        ## 24) ratio_cheekbone_width_face_width_eye_level\n",
    "        dict_[\"ratio_cheekbone_width_face_width_eye_level\"] = 1.0*dict_[\"cheekbone_width\"]/dict_[\"face_width_eye_level\"]\n",
    "        feature_vector.append(dict_[\"ratio_cheekbone_width_face_width_eye_level\"])\n",
    "        feature_vector_name.append(\"ratio_cheekbone_width_face_width_eye_level\")\n",
    "        \n",
    "        ## 25) thickness of middle of top lip\n",
    "        dict_[\"thickness_top_lip_middle\"] = distance.euclidean(dict_[\"mouth_upper_lip_bottom\"], \n",
    "                                                               dict_[\"mouth_upper_lip_top\"])\n",
    "        feature_vector.append(dict_[\"thickness_top_lip_middle\"])\n",
    "        feature_vector_name.append(\"thickness_top_lip_middle\")\n",
    "        \n",
    "        ## 26) thickness of right side of top lip\n",
    "        dict_[\"thickness_top_lip_right\"] = distance.euclidean(dict_[\"mouth_upper_lip_right_contour3\"], \n",
    "                                                               dict_[\"mouth_upper_lip_right_contour2\"])\n",
    "        feature_vector.append(dict_[\"thickness_top_lip_right\"])\n",
    "        feature_vector_name.append(\"thickness_top_lip_right\")\n",
    "        \n",
    "        ## 27) thickness of left side of top lip\n",
    "        dict_[\"thickness_top_lip_left\"] = distance.euclidean(dict_[\"mouth_upper_lip_left_contour3\"], \n",
    "                                                               dict_[\"mouth_upper_lip_left_contour2\"])\n",
    "        feature_vector.append(dict_[\"thickness_top_lip_left\"])\n",
    "        feature_vector_name.append(\"thickness_top_lip_left\")\n",
    "        \n",
    "        ## 28) average thickness of top lip\n",
    "        dict_[\"average_thickness_top_lip\"] = np.mean([dict_[\"thickness_top_lip_middle\"],\n",
    "                                                     dict_[\"thickness_top_lip_right\"],\n",
    "                                                     dict_[\"thickness_top_lip_left\"]])\n",
    "        feature_vector.append(dict_[\"average_thickness_top_lip\"])\n",
    "        feature_vector_name.append(\"average_thickness_top_lip\")\n",
    "        \n",
    "        ## 29) thickness of lower lip\n",
    "        dict_[\"thickness_of_lower_lip\"] = distance.euclidean(dict_[\"mouth_lower_lip_top\"], \n",
    "                                                          dict_[\"mouth_lower_lip_bottom\"])\n",
    "        feature_vector.append(dict_[\"thickness_of_lower_lip\"])\n",
    "        feature_vector_name.append(\"thickness_of_lower_lip\")\n",
    "        \n",
    "        ## 30) thickness of both lips \n",
    "        dict_[\"thickness_of_both_lips\"] = distance.euclidean(dict_[\"mouth_upper_lip_top\"], \n",
    "                                                          dict_[\"mouth_lower_lip_bottom\"])\n",
    "        feature_vector.append(dict_[\"thickness_of_both_lips\"])\n",
    "        feature_vector_name.append(\"thickness_of_both_lips\")\n",
    "        \n",
    "        ## 31) length of lips\n",
    "        dict_[\"length_of_lips\"] = distance.euclidean(dict_[\"mouth_left_corner\"], \n",
    "                                                          dict_[\"mouth_right_corner\"])\n",
    "        feature_vector.append(dict_[\"length_of_lips\"])\n",
    "        feature_vector_name.append(\"length_of_lips\")\n",
    "        \n",
    "        ## 32) chin_length\n",
    "        dict_[\"chin_length\"] = distance.euclidean(dict_[\"contour_chin\"], \n",
    "                                                          dict_[\"mouth_lower_lip_bottom\"])\n",
    "        feature_vector.append(dict_[\"chin_length\"])\n",
    "        feature_vector_name.append(\"chin_length\")\n",
    "        \n",
    "        ## 33) right jaw length – from bottom of face \n",
    "        dict_[\"right_jaw_length\"] = distance.euclidean(dict_[\"contour_chin\"], \n",
    "                                                          dict_[\"contour_right8\"])\n",
    "        feature_vector.append(dict_[\"right_jaw_length\"])\n",
    "        feature_vector_name.append(\"right_jaw_length\")\n",
    "        \n",
    "        ## 34) right jaw length – from bottom of face \n",
    "        dict_[\"left_jaw_length\"] = distance.euclidean(dict_[\"contour_chin\"], \n",
    "                                                          dict_[\"contour_left8\"])\n",
    "        feature_vector.append(dict_[\"left_jaw_length\"])\n",
    "        feature_vector_name.append(\"left_jaw_length\")\n",
    "        \n",
    "        ## 36) ratio of (distance from nostrils to eyebrow top) to (distance from face bottome to nostrils)\n",
    "        dict_[\"ratio_of_distance_from_nostrils_to_eyebrow_top_to_distance_from_face_bottome_to_nostrils\"]\\\n",
    "        = 1.0*(distance.euclidean(dict_[\"crest_center\"], dict_[\"nose_tip\"]))/\\\n",
    "        (distance.euclidean(dict_[\"contour_chin\"], dict_[\"nose_tip\"]))\n",
    "        \n",
    "        feature_vector.append(dict_[\"ratio_of_distance_from_nostrils_to_eyebrow_top_to_distance_from_face_bottome_to_nostrils\"])\n",
    "        feature_vector_name.append(\"ratio_of_distance_from_nostrils_to_eyebrow_top_to_distance_from_face_bottome_to_nostrils\")\n",
    "        \n",
    "    feature_matrix.append(feature_vector)\n",
    "    image_name_list.append(image_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(distances, open('distances.pickle', 'wb'))\n",
    "distances = pickle.load(open('distances.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = np.array(feature_matrix)\n",
    "image_name_list = np.array(image_name_list)\n",
    "\n",
    "file1 = open(\"merged_api_impression.csv\", \"r\")\n",
    "merged_api = {}\n",
    "for line in file1:\n",
    "    \n",
    "    if line.startswith(\"img_name\"):\n",
    "        pass\n",
    "    else:\n",
    "        image_ID = line.split(',')[-8]\n",
    "        total_binary = line.split(',')[-5]\n",
    "        merged_api[str(image_ID) + \"_cb.jpeg\"] = total_binary\n",
    "\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8920, 34)\n",
      "(8920,)\n"
     ]
    }
   ],
   "source": [
    "print(feature_matrix.shape)\n",
    "print(image_name_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "image_names_used = []\n",
    "\n",
    "for indx, image_name in enumerate(image_name_list):\n",
    "    try:\n",
    "        Y.append(int(merged_api[image_name]))\n",
    "        X.append(feature_matrix[indx,:])\n",
    "        image_names_used.append(image_name)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 3423, 1: 2117})\n",
      "Resampled dataset shape Counter({0: 3423, 1: 3423})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "print('Original dataset shape %s' % Counter(Y))\n",
    "sm = SMOTE(random_state=42)\n",
    "# X = np.array(X)  #.reshape(-1, 1) \n",
    "X, Y = sm.fit_resample(X, Y)\n",
    "print('Resampled dataset shape %s' % Counter(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.35, random_state=42, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4449, 34)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 2224, 1: 2225})"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9806it [00:00, 85094.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9806"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=0\n",
    "for img_filename in tqdm(glob.iglob('/Users/tanvipriya/Documents/quarter_materials/3) Fall 2018/impression_personality/VC_old_data/e/*/*.jpeg')):\n",
    "    c+=1\n",
    "c "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Coefficient: \\n', array([[-4.38181523e-02, -1.58006203e-02, -1.74446109e-02,\n",
      "         6.37872698e-03, -2.12412037e-01,  1.85463088e-01,\n",
      "         1.13505306e-01, -3.75839512e-01,  3.18105757e-02,\n",
      "         4.51289873e-02,  6.91440273e-03, -8.05174200e-03,\n",
      "        -2.71092706e-02, -1.58861041e-02,  1.02484643e-02,\n",
      "        -3.25001110e-02,  2.10698011e-03,  1.69992534e-04,\n",
      "        -1.39104872e-02,  2.52474127e-02, -8.32077911e-04,\n",
      "         1.64399097e-03,  7.12889141e-03, -1.76971867e-01,\n",
      "         5.49031402e-02,  1.59097359e-02, -3.53863302e-02,\n",
      "         7.50889239e-02, -1.99939698e-03,  1.71884572e-02,\n",
      "        -4.33438981e-02,  1.24141241e-01,  1.54834849e-01,\n",
      "         4.30957316e-02]]))\n",
      "('Intercept: \\n', array([-0.14874075]))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(np.array(X_train), np.array(y_train))\n",
    "model.score(X_train, y_train)\n",
    "\n",
    "print('Coefficient: \\n', model.coef_)\n",
    "print('Intercept: \\n', model.intercept_)\n",
    "\n",
    "predicted= model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5348352106800167"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1.0*(predicted==y_test).sum()/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "model = tree.DecisionTreeClassifier(criterion='gini') \n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_train, y_train)\n",
    "predicted= model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58906967042136"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1.0*(predicted==y_test).sum()/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM (Support Vector Machine):-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "model = svm.SVC()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_train, y_train)\n",
    "predicted= model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6645807259073843"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1.0*(predicted==y_test).sum()/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN (k- Nearest Neighbors):-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNeighborsClassifier(n_neighbors=6)\n",
    "model.fit(X_train, y_train)\n",
    "predicted= model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6645807259073843"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1.0*(predicted==y_test).sum()/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model= RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "predicted= model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6299541093032958"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1.0*(predicted==y_test).sum()/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model= GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "predicted= model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6191072173550272"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1.0*(predicted==y_test).sum()/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = XGBClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Make predictions for test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6332916145181476"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1.0*(y_pred==y_test).sum()/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guru2",
   "language": "python",
   "name": "guru2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
