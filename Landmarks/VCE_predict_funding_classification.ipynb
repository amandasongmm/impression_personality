{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "import urllib, json\n",
    "import requests\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial import distance\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = {}\n",
    "\n",
    "def clean_up_values(string):\n",
    "    split = re.split('[, }]', string)\n",
    "    x = float(split[4])\n",
    "    y = float(split[1])\n",
    "    return (x,y)\n",
    "\n",
    "file1 = open(\"ent-landmarks.txt\", \"r\") \n",
    "for line in file1:\n",
    "    if line.startswith(\"image_name\"):\n",
    "        pass\n",
    "    else:\n",
    "        line_split = line.split(\"\\t\")\n",
    "        image_name = line_split[0]\n",
    "        distances[image_name] = {}\n",
    "\n",
    "        distances[image_name][\"contour_left2\"] = clean_up_values(line_split[1])\n",
    "        distances[image_name][\"contour_right2\"] = clean_up_values(line_split[2])\n",
    "        distances[image_name][\"right_eyebrow_left_corner\"] = clean_up_values(line_split[3])\n",
    "        distances[image_name][\"left_eyebrow_left_corner\"] = clean_up_values(line_split[4])\n",
    "        distances[image_name][\"contour_chin\"] = clean_up_values(line_split[5])\n",
    "        distances[image_name][\"mouth_lower_lip_bottom\"] = clean_up_values(line_split[6])\n",
    "        distances[image_name][\"mouth_lower_lip_top\"] = clean_up_values(line_split[7])\n",
    "        \n",
    "        width = distance.euclidean(distances[image_name][\"contour_left2\"], \n",
    "                                   distances[image_name][\"contour_right2\"])\n",
    "        distances[image_name][\"width\"] = width\n",
    "        right_brow = distances[image_name][\"right_eyebrow_left_corner\"]\n",
    "        left_brow = distances[image_name][\"left_eyebrow_left_corner\"]\n",
    "        \n",
    "        crest_center = (0.5*(right_brow[0]+left_brow[0]), 0.5*(right_brow[1]+left_brow[1]))\n",
    "        distances[image_name][\"crest_center\"] = crest_center\n",
    "        length = distance.euclidean(distances[image_name][\"mouth_lower_lip_bottom\"], \n",
    "                                   distances[image_name][\"crest_center\"])\n",
    "        distances[image_name][\"length\"] = length\n",
    "        distances[image_name][\"Width_to_Height_Ratio\"] = 1.0*width/length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(distances, open('distances.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open(\"merged_api_impression.csv\", \"r\")\n",
    "merged_api = {}\n",
    "for line in file1:\n",
    "    \n",
    "    if line.startswith(\"img_name\"):\n",
    "        pass\n",
    "    else:\n",
    "        image_ID = line.split(',')[-8]\n",
    "        total_binary = line.split(',')[-5]\n",
    "        merged_api[str(image_ID) + \"_cb.jpeg\"] = total_binary\n",
    "\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = pickle.load(open('distances.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1925"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "image_names = []\n",
    "Y = []\n",
    "for image in distances:\n",
    "    try:\n",
    "        Y.append(int(merged_api[image]))\n",
    "        X.append(distances[image]['Width_to_Height_Ratio'])\n",
    "        image_names.append(image)\n",
    "    except:\n",
    "        pass\n",
    "len(image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 1176, 1: 749})\n",
      "Resampled dataset shape Counter({0: 1176, 1: 1176})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "print('Original dataset shape %s' % Counter(Y))\n",
    "sm = SMOTE(random_state=42)\n",
    "X = np.array(X).reshape(-1, 1) \n",
    "X, Y = sm.fit_resample(X, Y)\n",
    "print('Resampled dataset shape %s' % Counter(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 353, 1: 353})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Coefficient: \\n', array([[0.09072267]]))\n",
      "('Intercept: \\n', array([-0.13498751]))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(np.array(X_train), np.array(y_train))\n",
    "model.score(X_train, y_train)\n",
    "\n",
    "print('Coefficient: \\n', model.coef_)\n",
    "print('Intercept: \\n', model.intercept_)\n",
    "\n",
    "predicted= model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5212464589235127"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1.0*(predicted==y_test).sum()/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "model = tree.DecisionTreeClassifier(criterion='gini') \n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_train, y_train)\n",
    "predicted= model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5169971671388102"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1.0*(predicted==y_test).sum()/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM (Support Vector Machine):-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "model = svm.SVC()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_train, y_train)\n",
    "predicted= model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5297450424929179"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1.0*(predicted==y_test).sum()/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN (k- Nearest Neighbors):-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNeighborsClassifier(n_neighbors=6)\n",
    "model.fit(X_train, y_train)\n",
    "predicted= model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5297450424929179"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1.0*(predicted==y_test).sum()/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model= RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "predicted= model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5184135977337111"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1.0*(predicted==y_test).sum()/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model= GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "predicted= model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5014164305949008"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1.0*(predicted==y_test).sum()/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = XGBClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Make predictions for test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5212464589235127"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1.0*(y_pred==y_test).sum()/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guru2",
   "language": "python",
   "name": "guru2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
